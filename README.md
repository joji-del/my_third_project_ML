# LinearClassification

Добро пожаловать в **LinearClassification** — репозиторий, содержащий Jupyter Notebook (`ML_3.ipynb`), посвященный изучению линейной классификации с использованием методов опорных векторов (SVM) и логистической регрессии. Этот проект включает работу с синтетическими данными и реальным датасетом для предсказания успешности маркетинговой кампании банка, а также отбор признаков с использованием метода Forward Selection.

## Обзор

Репозиторий включает Jupyter Notebook (`ML_3.ipynb`), который охватывает следующие темы:
- Генерация и анализ синтетических данных для бинарной классификации.
- Обучение модели LinearSVC с подбором параметра регуляризации `C` на основе метрики AUC-PR.
- Построение ROC и PR кривых, сравнение с метриками случайного классификатора.
- Работа с реальным датасетом банковского маркетинга: предобработка, кодирование категориальных признаков, стандартизация.
- Реализация Forward Selection для отбора признаков с использованием логистической регрессии.
- Оценка качества модели на тестовой выборке с отобранными признаками (ROC AUC).

Ноутбук содержит подробные комментарии, код для визуализации и анализа данных, а также результаты экспериментов.

## Набор данных

1. **Синтетические данные**:
   - Сгенерированы с помощью `sklearn.datasets.make_classification` (10,000 объектов, 10 признаков, 5 информативных, 5 избыточных).
   - Используются для изучения LinearSVC и подбора гиперпараметров.

2. **Реальный датасет**:
   - Датасет банковского маркетинга (источник не указан в ноутбуке, предположительно из UCI Machine Learning Repository: [Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)).
   - Содержит информацию о клиентах и маркетинговых кампаниях (возраст, профессия, семейное положение, экономические индикаторы и т.д.).
   - Целевая переменная: успех маркетинговой кампании (`y`, бинарная: "yes"/"no").

## Требования

Для работы с ноутбуком необходимы следующие библиотеки Python:
- `numpy`
- `pandas`
- `matplotlib`
- `seaborn`
- `scikit-learn`

Установите их с помощью команды:
```bash
pip install numpy pandas matplotlib seaborn scikit-learn
```

## Структура репозитория

- `ML_3.ipynb`: Основной Jupyter Notebook с анализом данных, обучением моделей и отбором признаков.
- `bank_data.csv`: Файл с данными (не включен в репозиторий, необходимо загрузить отдельно, например, из UCI Repository).
- `README.md`: Этот файл с описанием проекта.

## Использование

1. Скачайте датасет банковского маркетинга (например, `bank-additional-full.csv`) и поместите его в папку репозитория.
2. Склонируйте репозиторий:
   ```bash
   git clone https://github.com/<your-username>/LinearClassification.git
   ```
3. Перейдите в папку репозитория:
   ```bash
   cd LinearClassification
   ```
4. Запустите Jupyter Notebook:
   ```bash
   jupyter notebook ML_3.ipynb
   ```
5. Следуйте инструкциям в ноутбуке для выполнения анализа, обучения моделей и оценки результатов.

## Основные разделы ноутбука

1. **Работа с синтетическими данными**:
   - Генерация данных (`make_classification`).
   - Стандартизация признаков с помощью `StandardScaler`.
   - Разделение данных на обучающую (70%) и тестовую (30%) выборки, с дополнительным выделением валидационной выборки (25% от обучающей).
   - Подбор параметра `C` для `LinearSVC` с использованием метрики AUC-PR (лучший `C = 0.001`).
   - Построение ROC и PR кривых, вычисление AUC-ROC (`0.77199`) и AUC-PR (`0.83159`) на тестовой выборке.
   - Сравнение с метриками случайного классификатора (AUC-ROC ≈ 0.5, AUC-PR зависит от доли положительного класса).

2. **Работа с реальным датасетом**:
   - Загрузка и предварительная обработка данных: обработка пропущенных значений, кодирование категориальных признаков (`OneHotEncoder`), стандартизация числовых признаков.
   - Разделение данных на обучающую, валидационную и тестовую выборки.
   - Реализация Forward Selection для отбора 40 признаков на основе ROC AUC с использованием логистической регрессии.
   - Оценка финальной модели на тестовой выборке: ROC AUC = `0.77957` с 40 отобранными признаками.

3. **Визуализация**:
   - Построение ROC и PR кривых для синтетических данных.
   - Вывод результатов отбора признаков и метрик качества.


## Результаты

- **Синтетические данные**:
  - Оптимальный параметр `C = 0.001` для LinearSVC.
  - AUC-ROC: `0.77199`, AUC-PR: `0.83159` (значительно лучше случайного классификатора: AUC-ROC ≈ 0.5, AUC-PR ≈ доля положительного класса).
  - Построены ROC и PR кривые для визуального анализа.

- **Реальный датасет**:
  - Отобрано 40 признаков с помощью Forward Selection (время: ~87 секунд).
  - Выбранные признаки включают экономические индикаторы (`nr.employed`, `emp.var.rate`, `euribor3m`), временные характеристики (`month_may`, `month_nov`, `day_of_week_wed`), демографические данные (`age`, `job_unemployed`, `education_high.school`) и другие.
  - ROC AUC на тестовой выборке: `0.77957`, что демонстрирует хорошее качество модели.

